output_folder: experiments # name of the parent folder where all experiments will be stored
experiments: #list of experiments
  - name: Experiment1 # the name is a unique identifier to each experiment
    dataloaders: # defining the sources of data (datasets), their sampling logic and the preprocessing
      type: DateDataloader # the type defines the loading logic. DateDataloader separates data into distinct timestamps.
      batch_size: 1 # size of samples passed to BATCHED metrics. If one file contains a whole ensemble, then the batch consists in only this ensemble (hence the default number to 1).
      maxNsamples: 16 # maximum number of samples to be used for NON-BATCHED metrics. If it is superior to the total number of samples, the latter will be chosen.
      path_to_csv: /where/your/csv/is #where to find the csv file linking files to metadata. Files not registered in this csv will not be used.
      csv_file: Large_lt_test_labels.csv # the csv file. An example structure is shown in example_labels.csv
      date_start: '2021-08-14' # defining the period in which data is fetched 
      date_end: '2021-08-15' # this period can be any size. This is used e.g to restrict the dates selected in the csv file.
      number_of_dates : 20 # Number of dates to be selected within de defined period. The order of selection is fixed and depends on the ordering of the csv.
      Lead_Times : 15 # number of lead times that are considered for each forecast
      start_time : 21 # 21:00. Arome simulations in the dataset start at 21:00
      dh : 3 # Lead time step. This is used to match observation sources
      real_dataset_config: # defining the Dataset for "real" (physics-based NWP) reference.
        data_folder: /where/your/real/data/is/ #
        variables: ['u','v','t2m'] # list of strings, to name the variables considered
        sizeH: 256  #size in latitude ("height")
        sizeW: 256  #size in latitude ("height")
        var_indices: [1,2,3] #indices to find the variables in dataset samples (usually, in a channel-first view). each element of "variables" is mapped to one element of var_indices, here 'u':1, 'v':2, 't2m':3
        crop_indices: [0,256,0,256] # to perform any crop (latitude indices first)
        preprocessor_config:
          type: Preprocessor # base preprocessor class by default ("real" samples are not preprocessed)

      fake_dataset_config: # defining the Dataset for "fake" (data-driven emulator)
        type: FakeDataset #to be chosen in a few predefined types. Main types are FakeDataset (default, loading files by dates and leadtimes) and RandomDataset (mixing all timestamps),
        # but also MixDataset (building mixtures of NWP / data-driven ensembles) and ModDataset (modifiying/post-processing)
        # Be aware that required keywords might change, depending on which type you choose. Refer to each class's `required_keys` fields.
        data_folder:  /where/your/fake/data/is/
        variables: ['u','v','t2m']
        sizeH: 256  #size in latitude ("height")
        sizeW: 256  #size in latitude ("height")
        inv_step: 200  #additional parameter to keep fixed in the desired format
        filename_format: "genFsemble_{date}_{formatted_index}_{inv_step}" #format of the typical file name used for the dataset. The {...} expression is used to provide parameters that describ each file individually. F-string evaluation is performed to load each file.
        var_indices: [0,1,2] #indices to find the variables in dataset samples (usually, in a channel-first view). NB : these can be different from the real dataset config.
        crop_indices: [0,256,0,256] # to perform any crop (latitude indices first)
        preprocessor_config:
            type: ReverserrPreprocessor # class of preprocessors used to treat precipitation outputs. Refer to the doc / comments in the ./MetScore/preprocess/ folder.
            real_var_indices: [1,2,3] #where to find the variables in stat files (used for normalisation) --> usually the same as the Real datasets
            real_data_dir: /where/your/real/dataset/is
            stat_folder: "where/your/stat/file/are/"
            # For the next, refer to the doc / comments in the ./MetScore/preprocess/ folder.
            stat_version: "rr" # the name of the stat file is for ex: 'mean_[stat_version]_log_ppx.npy'
            rr_transform:
              log_transform_iteration: 1
              symetrization: False
              gaussian_std: 0
            normalization:
              type: "mean"
              per_pixel: False
              for_rr:
                blur_iteration: 1
      obs_dataset_config: # defining the Dataset for "observations" (ground truth). The
        data_folder: data/obs_reduced_npy
        crop_indices: [180, 436, 500, 756]
        variables: ['ff','dd','t2m']
        var_indices: [0,1,2]
        preprocessor_config:
            type: Preprocessor
    metrics:
      args: # common arguments to use in metrics. These arguments may be required by one or more metrics. If they may abe applied to several metrics, it is better to save them here; 
        debiasing: False
        threshold: [[ 1.39, 2.78, 4.17, 5.56, 8.33, 11.11 ], [ 278.15, 283.15, 288.15, 293.15, 297.15, 303.15 ]] # thresholds, e.g for brier score or ROC curves
        var_channel: 1 # which dimension of the tensors corresponds to different variables
        obs_var_channel: 1 # same, for observation data
        isOnReal: False # this args says whether the metrics should apply by default to evaluate "fake data", or "real data". Only apply to batched, non standalone metrics. Can be specified for metrics individually.
      metrics_list:
        - name: relDiagram
          type: relDiagram
        - name: ensembleCRPS
          type: ensembleCRPS
          fair: True # this is an additional argument, specific to the ensembleCRPS metric. It should be specified here, but it can also be specified in the args section.
        - name: brierScore
          type: brierScore
        - name: skillSpread
          type: skillSpread
        - name: rankHistogram
          type: rankHistogram
        - name: biasEnsemble
          type: biasEnsemble
          
  - name: Experiment2 ##### repeating the same, with a different experiment
    dataloaders: # defining the sources of data (datasets), their sampling logic and the preprocessing
      type: DateDataloader # the type defines the loading logic. DateDataloader separates data into distinct timestamps.
      batch_size: 1 # size of samples passed to BATCHED metrics. If one file contains a whole ensemble, then the batch consists in only this ensemble (hence the default number to 1).
      maxNsamples: 16 # maximum number of samples to be used for NON-BATCHED metrics. If it is superior to the total number of samples, the latter will be chosen.
      path_to_csv: /where/your/csv/is #where to find the csv file linking files to metadata. Files not registered in this csv will not be used.
      csv_file: Large_lt_test_labels.csv # the csv file. An example structure is shown in example_labels.csv
      date_start: '2021-08-14' # defining the period in which data is fetched 
      date_end: '2021-08-15' # this period can be any size. This is used e.g to restrict the dates selected in the csv file.
      number_of_dates : 20 # Number of dates to be selected within de defined period. The order of selection is fixed and depends on the ordering of the csv.
      Lead_Times : 15 # number of lead times that are considered for each forecast
      start_time : 21 # 21:00. Arome simulations in the dataset start at 21:00
      dh : 3 # Lead time step. This is used to match observation sources
      real_dataset_config: # defining the Dataset for "real" (physics-based NWP) reference.
        data_folder: /where/your/real/data/is/ #
        variables: ['u','v','t2m'] # list of strings, to name the variables considered
        sizeH: 256  #size in latitude ("height")
        sizeW: 256  #size in latitude ("height")
        var_indices: [1,2,3] #indices to find the variables in dataset samples (usually, in a channel-first view). each element of "variables" is mapped to one element of var_indices, here 'u':1, 'v':2, 't2m':3
        crop_indices: [0,256,0,256] # to perform any crop (latitude indices first)
        preprocessor_config:
          type: Preprocessor # base preprocessor class by default ("real" samples are not preprocessed)

      fake_dataset_config: # defining the Dataset for "fake" (data-driven emulator)
        type: FakeDataset #to be chosen in a few predefined types. Main types are FakeDataset (default, loading files by dates and leadtimes) and RandomDataset (mixing all timestamps),
        # but also MixDataset (building mixtures of NWP / data-driven ensembles) and ModDataset (modifiying/post-processing)
        # Be aware that required keywords might change, depending on which type you choose. Refer to each class's `required_keys` fields.
        data_folder:  /where/your/fake/data/is/
        variables: ['u','v','t2m']
        sizeH: 256  #size in latitude ("height")
        sizeW: 256  #size in latitude ("height")
        inv_step: 200  #additional parameter to keep fixed in the desired format
        filename_format: "genFsemble_{date}_{formatted_index}_{inv_step}" #format of the typical file name used for the dataset. The {...} expression is used to provide parameters that describ each file individually. F-string evaluation is performed to load each file.
        var_indices: [0,1,2] #indices to find the variables in dataset samples (usually, in a channel-first view). NB : these can be different from the real dataset config.
        crop_indices: [0,256,0,256] # to perform any crop (latitude indices first)
        preprocessor_config:
            type: ReverserrPreprocessor # class of preprocessors used to treat precipitation outputs. Refer to the doc / comments in the ./MetScore/preprocess/ folder.
            real_var_indices: [1,2,3] #where to find the variables in stat files (used for normalisation) --> usually the same as the Real datasets
            real_data_dir: /where/your/real/dataset/is
            stat_folder: "where/your/stat/file/are/"
            # For the next, refer to the doc / comments in the ./MetScore/preprocess/ folder.
            stat_version: "rr" # the name of the stat file is for ex: 'mean_[stat_version]_log_ppx.npy'
            rr_transform:
              log_transform_iteration: 1
              symetrization: False
              gaussian_std: 0
            normalization:
              type: "mean"
              per_pixel: False
              for_rr:
                blur_iteration: 1
      obs_dataset_config: # defining the Dataset for "observations" (ground truth). The
        data_folder: data/obs_reduced_npy
        crop_indices: [180, 436, 500, 756]
        variables: ['ff','dd','t2m']
        var_indices: [0,1,2]
        preprocessor_config:
            type: Preprocessor
    metrics:
      args: # common arguments to use in metrics. These arguments may be required by one or more metrics.
        debiasing: False
        conditioning_members: 16
        threshold: [[ 1.39, 2.78, 4.17, 5.56, 8.33, 11.11 ], [ 278.15, 283.15, 288.15, 293.15, 297.15, 303.15 ]] # for brier score
        var_channel: 1 # which dimension of the tensors corresponds to different variables
        obs_var_channel: 1 # same, for observation data
        isOnReal: False # this args says whether the metrics should apply by default to evaluate "fake data", or "real data". Only apply to batched, non standalone metrics. Can be specified for metrics individually.

      metrics_list:
        - name: relDiagram
          type: relDiagram
        - name: ensembleCRPS
          type: ensembleCRPS
          fair: True # this is an additional argument to the ensembleCRPS metric. It should be specified here, or in the args section.
        - name: brierScore
          type: brierScore
        - name: skillSpread
          type: skillSpread
        - name: rankHistogram
          type: rankHistogram
        - name: biasEnsemble
          type: biasEnsemble
